local pagetmp page2analyze TMPOUT1 TMPnohup referer url downloadList downloadLog downloadingLoopLog userAgent allPages FORCE wget_options i nbUrlGrabbed nbUrlStarted nbUrl2Process
pagetmp=$(mktemp -t wgett.pagetmp.$$.XXXXXX)
page2analyze=$(mktemp -t wgett.page2analyze.$$.XXXXXX)
TMPOUT1=$(mktemp -t wgett.TMPOUT1.$$.XXXXXX).out
TMPnohup=$(mktemp -t wgett.TMPnohup.$$.XXXXXX).out
urlDone=$(mktemp -t wgett.urlDone.$$.XXXXXX).out
urlFailed=$(mktemp -t wgett.urlFailed.$$.XXXXXX).out
urlInterrupted=$(mktemp -t wgett.urlInterrupted.$$.XXXXXX).out
downloadList=wgett.urls2dl.log
wget_options="-e robots=off --restrict-file-names=windows"

# url="http://mp3squid.com/mp3/joey_negro%20%20sunburst%20band%20monte%20carlo.html"
(($# == 0)) && echo2 "wgett <./wgett.urls2dl.log* | -c> | <http://url...mp3> | <http://url [all]> [-fd]" && printf "${c}  websites currently handled:${SMUL}${B}\nmp3squid.com\n" && return 99

userAgent="Mozilla/5.0"
allPages=false

# DIREXPLOIT=${DIREXPLOIT:-/raid/data/sources/root}
# [ -t 0 ] && TTY=true || TTY=false
# UNAME=$(uname -s)
# ! test ${K} && . ${DIREXPLOIT}/FPATH/profile/setColors && setColors

FORCE=false
while (($# > 0)); do
  case "x${1}" in
    "xall") allPages=true ;;
    "x-c") [ ! -s "${downloadList}" ] && echo2 "${downloadList} missing..." && return 1 || url=$(head -1 ${downloadList}) ;;
    "x-f") FORCE=true ;;
    "x-d") Debug=true ;;
    *) [ -s "$1" ] && url=$(head -1 "$1") || url="$1"
      ;;
  esac
  shift
done

referer=${referer:-${url}}
downloadLog=wgett.$(htmlspecialchars "${referer}").log
downloadingLoopLog=wgett.$(htmlspecialchars "${referer}").wget;
ps -ef | grep wget | grep "${downloadLog}" | grep -v grep && echo2 "wget ${downloadLog} still running..." && return 2

if [[ "${url}" =~ mp3$ ]]; then
  nohup wget ${wget_options} --user-agent="${userAgent}" --referer="${referer}" "${url}" --append-output=${TMPOUT1} 2>&1 0</dev/null &
  echo ${TMPOUT1}
  tail -f ${TMPOUT1}
elif [[ "${url}" =~ mp3squid ]]; then
  $Debug && echo ""${url}" =~ mp3squid"
  $Debug && echo "(FORCE=$FORCE || [ ! -s \"${downloadList}\" ])" && read a
  if ($FORCE || [ ! -s "${downloadList}" ]); then
    $Debug && echo "REBUILD: ${downloadList}"
    $Debug && echo allPages=$allPages && read a
    if $allPages; then
      i=0
      while ! (grep -qi "No Results" ${page2analyze}); do
        $Debug && echo "LOOP: wget ${wget_options} --user-agent=\"${userAgent}\" \"${url}?p=${i}\" --output-document=${pagetmp} --append-output=${TMPOUT1} 2>&1" && read a
        wget ${wget_options} --user-agent="${userAgent}" "${url}?p=${i}" --output-document=${pagetmp} --append-output=${TMPOUT1} 2>&1
        $Debug && echo "cat ${pagetmp} >>${page2analyze}"
        cat ${pagetmp} >>${page2analyze}
        let ++i
      done
    else
      echo "NOLOOP: wget ${wget_options} --user-agent=\"${userAgent}\" \"${url}\" --output-document=${page2analyze} --append-output=${TMPOUT1} 2>&1" && read a
      wget ${wget_options} --user-agent="${userAgent}" "${url}" --output-document=${page2analyze} --append-output=${TMPOUT1} 2>&1
    fi
    echo "${referer}" >${downloadList}
    awk '/noindex/ && /href=/ {n=split($0,url,"\""); print url[2];}' ${page2analyze} | sort | uniq >>${downloadList}
  else
    printf ${K}
  fi
  
  if [ -s "${downloadList}" ]; then
    $Debug && cat ${downloadList}
    nbUrlGrabbed=$(cat ${downloadList} | wc -l)
    nbUrlGrabbed=$((nbUrlGrabbed - 1))
    nbUrlStarted=$(grep ^GO ${downloadLog} | sort | uniq | wc -l)
    awk '/^OK/ {gsub(/\(/,"\\("); gsub(/\)/,"\\)"); print $2}' ${downloadLog} | sort | uniq >${urlDone}
    nbUrlDone=$(cat ${urlDone} | wc -l)
    awk '/^KO/ {gsub(/\(/,"\\("); gsub(/\)/,"\\)"); print $2}' ${downloadLog} | sort | uniq | egrep -v -f ${urlDone} >${urlFailed}
    awk '/^GO/ {gsub(/\(/,"\\("); gsub(/\)/,"\\)"); print $2}' ${downloadLog} | sort | uniq | egrep -v -f ${urlDone} -f ${urlDone} >${urlInterrupted}
    # nbUrl2Reprocess = KO + GO aborted
    nbUrl2Reprocess=$(cat ${urlInterrupted} | wc -l)
    nbUrlDonePlusFailed=$((nbUrlDone + nbUrl2Reprocess))
    lastUrl2Process=$(grep ^GO ${downloadLog} |awk 'END {print $2}')
    echo "${downloadList}: ${Y}$i${y}${i:+ pages processed: }${y}${nbUrlStarted}${w}~(${g}${nbUrlDone}${w}+${R}${nbUrl2Reprocess}${w})=${Y}${nbUrlDonePlusFailed}${w}/${nbUrlGrabbed}${w} mp3 ${y}started${w}~(${g}done${w}+${R}failed${w})=${Y}processed${w}/total${END}"
    
    ((nbUrlDone == nbUrlGrabbed)) && echo "Nothing to be done ! (${nbUrlDone}/${nbUrlGrabbed} mp3 downloaded)" && return 0
    ((nbUrlDonePlusFailed == nbUrlGrabbed)) && echo "Nothing to be done ! (${nbUrlDone}/${nbUrlGrabbed} mp3 downloaded. Use ${c}-r${w} to retry the ${nbUrl2Reprocess} failed)" && return 0
    
    $Debug && read a
    
    unset i
    # nohup -- sh -c 'arg1=$0; arg2=$1; commands...' arg1 arg2 >>${TMPnohup} 2>&1 0</dev/null &
    nohup -- sh -c "$(typeset -f wgettLooper); wgettLooper ${downloadList} ${downloadLog} ${downloadingLoopLog} ${userAgent}">>${TMPnohup} 2>&1 0</dev/null &

    echo "${TMPnohup}: ${B}kill $!${END}"
    while [ ! -s "${TMPnohup}" ]; do
      sleep 1
    done
    
    grep -v ERROR ${TMPnohup} && tail -f ${downloadLog} || cat ${TMPnohup}
  else
    echo "No files found"
  fi
fi
